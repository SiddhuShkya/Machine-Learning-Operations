{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fd41c759",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-12-28 13:46:52.826125: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "/home/siddhu/Desktop/mlflow-starter/venv/lib/python3.10/site-packages/hyperopt/atpe.py:19: UserWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html. The pkg_resources package is slated for removal as early as 2025-11-30. Refrain from using this package or pin to Setuptools<81.\n",
      "  import pkg_resources\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "import numpy as np \n",
    "import pandas as pd\n",
    "from hyperopt import STATUS_OK, Trials, fmin, hp, tpe\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import mlflow\n",
    "from mlflow.models import infer_signature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "334d0ca5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fixed acidity</th>\n",
       "      <th>volatile acidity</th>\n",
       "      <th>citric acid</th>\n",
       "      <th>residual sugar</th>\n",
       "      <th>chlorides</th>\n",
       "      <th>free sulfur dioxide</th>\n",
       "      <th>total sulfur dioxide</th>\n",
       "      <th>density</th>\n",
       "      <th>pH</th>\n",
       "      <th>sulphates</th>\n",
       "      <th>alcohol</th>\n",
       "      <th>quality</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7.4</td>\n",
       "      <td>0.70</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.9</td>\n",
       "      <td>0.076</td>\n",
       "      <td>11.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>0.9978</td>\n",
       "      <td>3.51</td>\n",
       "      <td>0.56</td>\n",
       "      <td>9.4</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7.8</td>\n",
       "      <td>0.88</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2.6</td>\n",
       "      <td>0.098</td>\n",
       "      <td>25.0</td>\n",
       "      <td>67.0</td>\n",
       "      <td>0.9968</td>\n",
       "      <td>3.20</td>\n",
       "      <td>0.68</td>\n",
       "      <td>9.8</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7.8</td>\n",
       "      <td>0.76</td>\n",
       "      <td>0.04</td>\n",
       "      <td>2.3</td>\n",
       "      <td>0.092</td>\n",
       "      <td>15.0</td>\n",
       "      <td>54.0</td>\n",
       "      <td>0.9970</td>\n",
       "      <td>3.26</td>\n",
       "      <td>0.65</td>\n",
       "      <td>9.8</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>11.2</td>\n",
       "      <td>0.28</td>\n",
       "      <td>0.56</td>\n",
       "      <td>1.9</td>\n",
       "      <td>0.075</td>\n",
       "      <td>17.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>0.9980</td>\n",
       "      <td>3.16</td>\n",
       "      <td>0.58</td>\n",
       "      <td>9.8</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7.4</td>\n",
       "      <td>0.70</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.9</td>\n",
       "      <td>0.076</td>\n",
       "      <td>11.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>0.9978</td>\n",
       "      <td>3.51</td>\n",
       "      <td>0.56</td>\n",
       "      <td>9.4</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   fixed acidity  volatile acidity  citric acid  residual sugar  chlorides  \\\n",
       "0            7.4              0.70         0.00             1.9      0.076   \n",
       "1            7.8              0.88         0.00             2.6      0.098   \n",
       "2            7.8              0.76         0.04             2.3      0.092   \n",
       "3           11.2              0.28         0.56             1.9      0.075   \n",
       "4            7.4              0.70         0.00             1.9      0.076   \n",
       "\n",
       "   free sulfur dioxide  total sulfur dioxide  density    pH  sulphates  \\\n",
       "0                 11.0                  34.0   0.9978  3.51       0.56   \n",
       "1                 25.0                  67.0   0.9968  3.20       0.68   \n",
       "2                 15.0                  54.0   0.9970  3.26       0.65   \n",
       "3                 17.0                  60.0   0.9980  3.16       0.58   \n",
       "4                 11.0                  34.0   0.9978  3.51       0.56   \n",
       "\n",
       "   alcohol  quality  \n",
       "0      9.4        5  \n",
       "1      9.8        5  \n",
       "2      9.8        5  \n",
       "3      9.8        6  \n",
       "4      9.4        5  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load the data\n",
    "data = pd.read_csv(\"https://raw.githubusercontent.com/mlflow/mlflow/master/tests/datasets/winequality-red.csv\", sep=\";\")\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e5c3506f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set shape: (959, 11)\n",
      "Validation set shape: (320, 11)\n",
      "Test set shape: (320, 11)\n"
     ]
    }
   ],
   "source": [
    "# Separate features (X) and target (y)\n",
    "X = data.drop(columns=[\"quality\"], axis=1).values  # All columns except 'quality'\n",
    "y = data[\"quality\"].values.ravel()  # Target column 'quality' as 1D array\n",
    "\n",
    "# Split data into training and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X,\n",
    "    y,\n",
    "    test_size=0.2,\n",
    "    random_state=42,  # 20% test, 80% remaining for training/validation\n",
    ")\n",
    "\n",
    "# Split training data further into training and validation sets\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(\n",
    "    X_train,\n",
    "    y_train,\n",
    "    test_size=0.25,\n",
    "    random_state=42,  # 25% of 80% training → 20% of total for validation\n",
    ")\n",
    "\n",
    "# Print shapes to verify splits\n",
    "print(\"Training set shape:\", X_train.shape)  # Shape of training set\n",
    "print(\"Validation set shape:\", X_valid.shape)  # Shape of validation set\n",
    "print(\"Test set shape:\", X_test.shape)  # Shape of test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "95a3ded0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(params, epochs, X_train, y_train, X_valid, y_valid):\n",
    "    ## Define the model architecture\n",
    "    mean = np.mean(X_train, axis=0)\n",
    "    var = np.var(X_train, axis=0) \n",
    "    model = keras.Sequential([\n",
    "        keras.Input([X_train.shape[1]]),\n",
    "        keras.layers.Normalization(mean=mean, variance=var),\n",
    "        keras.layers.Dense(64, activation='relu'),\n",
    "        keras.layers.Dense(32, activation='relu'),\n",
    "        keras.layers.Dense(1)\n",
    "    ])\n",
    "    ## Compile the model\n",
    "    model.compile(\n",
    "        optimizer=keras.optimizers.SGD(\n",
    "            learning_rate=params['lr'], \n",
    "            momentum=params['momentum']), \n",
    "        loss='mean_squared_error', \n",
    "        metrics=[keras.metrics.RootMeanSquaredError()]\n",
    "    )\n",
    "    ## Train the ANN model with the given parameters with MLflow tracking\n",
    "    with mlflow.start_run(nested=True):\n",
    "        model.fit(\n",
    "            X_train, \n",
    "            y_train, \n",
    "            validation_data=(X_valid, y_valid), \n",
    "            epochs=epochs, \n",
    "            batch_size=32, \n",
    "            verbose=0\n",
    "        )\n",
    "        # Evaluate the model on validation data\n",
    "        val_loss, val_rmse = model.evaluate(X_valid, y_valid,batch_size=32)\n",
    "        # Log parameters and metrics to MLflow\n",
    "        mlflow.log_params(params)\n",
    "        mlflow.log_metric(\"val_loss\", val_loss)\n",
    "        mlflow.log_metric(\"val_RMSE\", val_rmse)\n",
    "        \n",
    "        # Log the model\n",
    "        signature = infer_signature(X_train, model.predict(X_train))\n",
    "        mlflow.keras.log_model(model, name=\"model\", signature=signature)\n",
    "        \n",
    "        return {'loss': val_rmse, 'status': STATUS_OK, 'model': model}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1b98810e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective(params):\n",
    "    epochs = 10\n",
    "    result = train_model(\n",
    "        params=params, \n",
    "        epochs=epochs, \n",
    "        X_train=X_train, \n",
    "        y_train=y_train, \n",
    "        X_valid=X_valid, \n",
    "        y_valid=y_valid\n",
    "    )\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b6d99218",
   "metadata": {},
   "outputs": [],
   "source": [
    "space = {\n",
    "    'lr': hp.loguniform('lr', np.log(0.0001), np.log(0.1)),\n",
    "    'momentum': hp.uniform('momentum', 0.0, 0.9)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "be4a5a15",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/12/28 13:46:56 INFO mlflow.store.db.utils: Creating initial MLflow database tables...\n",
      "2025/12/28 13:46:56 INFO mlflow.store.db.utils: Updating database tables\n",
      "2025/12/28 13:46:56 INFO alembic.runtime.migration: Context impl SQLiteImpl.\n",
      "2025/12/28 13:46:56 INFO alembic.runtime.migration: Will assume non-transactional DDL.\n",
      "2025/12/28 13:46:56 INFO alembic.runtime.migration: Context impl SQLiteImpl.\n",
      "2025/12/28 13:46:56 INFO alembic.runtime.migration: Will assume non-transactional DDL.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/5 [00:00<?, ?trial/s, best loss=?]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "W0000 00:00:1766908917.067066  285980 gpu_device.cc:2342] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
      "Skipping registering GPU devices...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m 1/10\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.6008 - root_mean_squared_error: 0.7751\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.9560 - root_mean_squared_error: 0.9778 \n",
      "\n",
      "\u001b[1m 1/30\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 32ms/step\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
      "\n",
      "\u001b[1m 1/10\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.5170 - root_mean_squared_error: 0.7191\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.7175 - root_mean_squared_error: 0.8471 \n",
      "\n",
      "\u001b[1m 1/30\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 32ms/step               \n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\n",
      "\u001b[1m 1/10\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.4202 - root_mean_squared_error: 0.6482\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.4431 - root_mean_squared_error: 0.6656 \n",
      "\n",
      "\u001b[1m 1/30\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 36ms/step               \n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\n",
      "\u001b[1m 1/10\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.4958 - root_mean_squared_error: 0.7041\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.6834 - root_mean_squared_error: 0.8267 \n",
      "\n",
      "\u001b[1m 1/30\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 33ms/step               \n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\n",
      "\u001b[1m 1/10\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 1.2097 - root_mean_squared_error: 1.0999\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1.6152 - root_mean_squared_error: 1.2709 \n",
      "\n",
      "\u001b[1m 1/30\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 31ms/step               \n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step       \n",
      "\n",
      "100%|██████████| 5/5 [00:37<00:00,  7.54s/trial, best loss: 0.6656411290168762]\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step \n",
      "Best hyperparameters: {'lr': np.float64(0.038321812403011545), 'momentum': np.float64(0.838070407316606)}\n",
      "Best validation RMSE: 0.6656411290168762\n"
     ]
    }
   ],
   "source": [
    "## Set the MLflow experiment \n",
    "mlflow.set_experiment(\"DL-Wine-Quality-Prediction-Hyperopt\")\n",
    "## Start the MLflow run\n",
    "with mlflow.start_run(run_name=\"DL-Hyperopt-Optimization\"):\n",
    "    ## Conduct hyperparameter optimization using Hyperopt\n",
    "    trials = Trials()\n",
    "    best_result = fmin(\n",
    "        fn=objective,\n",
    "        space=space,\n",
    "        algo=tpe.suggest,\n",
    "        max_evals=5,\n",
    "        trials=trials\n",
    "    )\n",
    "    ## Fetch details of the best run\n",
    "    best_run = sorted(trials.results, key=lambda x: x['loss'])[0]\n",
    "    ## Log the best hyperparameters\n",
    "    mlflow.log_params(best_result)\n",
    "    ## Log the best loss and model\n",
    "    mlflow.log_metric(\"best_val_RMSE\", best_run['loss'])\n",
    "    signature = infer_signature(X_train, best_run['model'].predict(X_train))\n",
    "    mlflow.keras.log_model(best_run['model'], name=\"best_model\", signature=signature)\n",
    "    ## Print the best hyperparameters\n",
    "    print(\"Best hyperparameters:\", best_result)\n",
    "    print(\"Best validation RMSE:\", best_run['loss'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b3818b9c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
      "[[5.4740524]\n",
      " [5.2378716]\n",
      " [5.728071 ]\n",
      " [5.4299517]\n",
      " [5.730378 ]\n",
      " [5.2789664]\n",
      " [5.3519955]\n",
      " [4.798749 ]\n",
      " [6.049017 ]\n",
      " [5.637619 ]\n",
      " [6.170869 ]\n",
      " [5.027384 ]\n",
      " [5.74936  ]\n",
      " [5.323105 ]\n",
      " [5.5683303]\n",
      " [6.1771736]\n",
      " [5.3666763]\n",
      " [5.6996927]\n",
      " [6.773551 ]\n",
      " [5.1585517]\n",
      " [4.627742 ]\n",
      " [5.4207835]\n",
      " [5.520452 ]\n",
      " [6.2966776]\n",
      " [5.3533   ]\n",
      " [5.721052 ]\n",
      " [6.3340917]\n",
      " [5.231279 ]\n",
      " [5.4158807]\n",
      " [6.471649 ]\n",
      " [5.3615427]\n",
      " [5.283028 ]\n",
      " [6.007335 ]\n",
      " [4.9404984]\n",
      " [5.675933 ]\n",
      " [5.09798  ]\n",
      " [6.1822734]\n",
      " [5.804502 ]\n",
      " [5.4885106]\n",
      " [5.8571854]\n",
      " [5.536747 ]\n",
      " [5.5070853]\n",
      " [6.3448954]\n",
      " [5.3130145]\n",
      " [5.9635377]\n",
      " [5.8135386]\n",
      " [6.5308776]\n",
      " [5.7776403]\n",
      " [4.944296 ]\n",
      " [5.448472 ]\n",
      " [5.1540437]\n",
      " [5.4437866]\n",
      " [5.4360867]\n",
      " [6.579914 ]\n",
      " [5.085454 ]\n",
      " [5.3479176]\n",
      " [6.25021  ]\n",
      " [5.5750866]\n",
      " [5.82306  ]\n",
      " [5.143217 ]\n",
      " [5.8515005]\n",
      " [6.1049967]\n",
      " [5.2070255]\n",
      " [5.149163 ]\n",
      " [6.3652115]\n",
      " [5.494742 ]\n",
      " [6.285998 ]\n",
      " [5.622909 ]\n",
      " [6.314387 ]\n",
      " [5.299115 ]\n",
      " [6.0299387]\n",
      " [5.019784 ]\n",
      " [6.1250906]\n",
      " [5.6894736]\n",
      " [6.1858134]\n",
      " [5.352307 ]\n",
      " [6.79823  ]\n",
      " [5.802989 ]\n",
      " [6.08535  ]\n",
      " [6.5109735]\n",
      " [5.365796 ]\n",
      " [6.522215 ]\n",
      " [5.428567 ]\n",
      " [5.2392874]\n",
      " [5.963512 ]\n",
      " [6.299386 ]\n",
      " [5.2036476]\n",
      " [6.033299 ]\n",
      " [6.402279 ]\n",
      " [4.946291 ]\n",
      " [6.028727 ]\n",
      " [6.61046  ]\n",
      " [5.2156906]\n",
      " [5.6518736]\n",
      " [5.346234 ]\n",
      " [5.9997573]\n",
      " [5.3460383]\n",
      " [5.8296747]\n",
      " [5.0700893]\n",
      " [5.639296 ]\n",
      " [4.889594 ]\n",
      " [5.071338 ]\n",
      " [5.819484 ]\n",
      " [5.6191707]\n",
      " [5.3681784]\n",
      " [6.1544795]\n",
      " [6.0336223]\n",
      " [5.4693456]\n",
      " [6.3355293]\n",
      " [5.3000293]\n",
      " [6.340312 ]\n",
      " [5.237568 ]\n",
      " [6.1407385]\n",
      " [5.157266 ]\n",
      " [5.540011 ]\n",
      " [6.079041 ]\n",
      " [5.9169445]\n",
      " [5.5628643]\n",
      " [4.922384 ]\n",
      " [5.9560165]\n",
      " [6.2031546]\n",
      " [5.566212 ]\n",
      " [5.772251 ]\n",
      " [5.122142 ]\n",
      " [5.4647975]\n",
      " [5.178939 ]\n",
      " [6.136371 ]\n",
      " [5.7915325]\n",
      " [5.260886 ]\n",
      " [5.7093277]\n",
      " [6.1250906]\n",
      " [5.123139 ]\n",
      " [5.2412596]\n",
      " [6.3107157]\n",
      " [5.448472 ]\n",
      " [5.0246067]\n",
      " [4.9935923]\n",
      " [5.299697 ]\n",
      " [5.1208715]\n",
      " [5.816334 ]\n",
      " [6.4000835]\n",
      " [6.276865 ]\n",
      " [6.48732  ]\n",
      " [5.0892477]\n",
      " [5.9668193]\n",
      " [5.24293  ]\n",
      " [5.953975 ]\n",
      " [5.1419926]\n",
      " [5.9640994]\n",
      " [5.3448024]\n",
      " [5.7565894]\n",
      " [6.1091185]\n",
      " [5.296148 ]\n",
      " [5.701527 ]\n",
      " [6.1250906]\n",
      " [5.9591846]\n",
      " [5.4376774]\n",
      " [6.0480227]\n",
      " [5.3644996]\n",
      " [6.1119046]\n",
      " [6.333517 ]\n",
      " [5.7502794]\n",
      " [6.0365405]\n",
      " [5.2482367]\n",
      " [5.517693 ]\n",
      " [5.731385 ]\n",
      " [4.8410387]\n",
      " [5.088109 ]\n",
      " [5.3464823]\n",
      " [5.265951 ]\n",
      " [5.3060317]\n",
      " [4.7814746]\n",
      " [6.1890674]\n",
      " [5.4700947]\n",
      " [6.879364 ]\n",
      " [6.0342684]\n",
      " [6.238797 ]\n",
      " [5.4270697]\n",
      " [5.664519 ]\n",
      " [4.9508495]\n",
      " [4.5922637]\n",
      " [6.386809 ]\n",
      " [5.4905577]\n",
      " [6.5753455]\n",
      " [4.843603 ]\n",
      " [6.5482264]\n",
      " [5.088003 ]\n",
      " [5.8839474]\n",
      " [6.698716 ]\n",
      " [5.4700947]\n",
      " [5.6396976]\n",
      " [6.3626018]\n",
      " [5.618978 ]\n",
      " [6.5083485]\n",
      " [5.7736244]\n",
      " [5.012928 ]\n",
      " [4.742034 ]\n",
      " [5.5367203]\n",
      " [5.515051 ]\n",
      " [6.1544795]\n",
      " [5.5287857]\n",
      " [5.2154794]\n",
      " [5.290925 ]\n",
      " [5.186146 ]\n",
      " [6.526634 ]\n",
      " [5.730993 ]\n",
      " [4.952422 ]\n",
      " [5.8625336]\n",
      " [6.121369 ]\n",
      " [6.0482087]\n",
      " [6.487794 ]\n",
      " [5.017996 ]\n",
      " [6.2194123]\n",
      " [6.2876053]\n",
      " [5.7513146]\n",
      " [5.7993603]\n",
      " [5.8544374]\n",
      " [5.259835 ]\n",
      " [5.629732 ]\n",
      " [5.5222306]\n",
      " [5.2696586]\n",
      " [6.1578894]\n",
      " [6.2515225]\n",
      " [6.160774 ]\n",
      " [4.9443192]\n",
      " [4.966554 ]\n",
      " [5.1569357]\n",
      " [6.629884 ]\n",
      " [5.5737123]\n",
      " [5.1915526]\n",
      " [5.709185 ]\n",
      " [4.9273343]\n",
      " [6.2110267]\n",
      " [6.032114 ]\n",
      " [6.110865 ]\n",
      " [6.1544795]\n",
      " [5.0099773]\n",
      " [5.963512 ]\n",
      " [5.200347 ]\n",
      " [5.2242146]\n",
      " [5.9719906]\n",
      " [5.0152984]\n",
      " [5.8479156]\n",
      " [6.331878 ]\n",
      " [5.5428333]\n",
      " [6.219808 ]\n",
      " [5.778141 ]\n",
      " [5.294775 ]\n",
      " [6.470295 ]\n",
      " [5.356146 ]\n",
      " [5.9438963]\n",
      " [5.2977843]\n",
      " [5.5788827]\n",
      " [5.667162 ]\n",
      " [4.9028783]\n",
      " [5.135897 ]\n",
      " [5.5098634]\n",
      " [5.401425 ]\n",
      " [5.954987 ]\n",
      " [6.5551004]\n",
      " [6.218811 ]\n",
      " [5.746522 ]\n",
      " [5.4270697]\n",
      " [6.662342 ]\n",
      " [5.949461 ]\n",
      " [6.644805 ]\n",
      " [5.4909415]\n",
      " [5.281078 ]\n",
      " [6.015887 ]\n",
      " [6.292577 ]\n",
      " [5.1046953]\n",
      " [5.706379 ]\n",
      " [5.493937 ]\n",
      " [5.386634 ]\n",
      " [5.571338 ]\n",
      " [5.22125  ]\n",
      " [5.8353815]\n",
      " [6.2834363]\n",
      " [6.372258 ]\n",
      " [5.4327765]\n",
      " [6.7005787]\n",
      " [5.1796203]\n",
      " [5.529077 ]\n",
      " [5.591466 ]\n",
      " [5.5178647]\n",
      " [6.131295 ]\n",
      " [5.4540963]\n",
      " [6.276865 ]\n",
      " [5.383585 ]\n",
      " [5.5529695]\n",
      " [6.8778334]\n",
      " [6.747403 ]\n",
      " [6.249306 ]\n",
      " [5.644635 ]\n",
      " [5.247492 ]\n",
      " [6.271016 ]\n",
      " [5.190357 ]\n",
      " [6.298275 ]\n",
      " [6.2767606]\n",
      " [6.3229303]\n",
      " [5.5483713]\n",
      " [4.969455 ]\n",
      " [6.3477125]\n",
      " [5.36263  ]\n",
      " [5.448238 ]\n",
      " [5.1734686]\n",
      " [6.1137176]\n",
      " [6.022474 ]\n",
      " [5.361293 ]\n",
      " [6.5819416]\n",
      " [5.488692 ]\n",
      " [5.4963627]\n",
      " [5.535563 ]\n",
      " [5.634819 ]\n",
      " [4.9404984]\n",
      " [5.932909 ]\n",
      " [5.548561 ]\n",
      " [5.24296  ]\n",
      " [6.2474947]\n",
      " [5.0946455]]\n"
     ]
    }
   ],
   "source": [
    "import mlflow.keras\n",
    "\n",
    "model_name = (\n",
    "    \"final-model\"  # The name you used for model registry 'registered_model_name'\n",
    ")\n",
    "model_version = \"1\"  # The best version of your registered model\n",
    "\n",
    "model_uri = f\"models:/{model_name}/{model_version}\"\n",
    "model = mlflow.keras.load_model(model_uri)\n",
    "\n",
    "y_pred = model.predict(X_test)\n",
    "print(y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b6fdd2d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
